{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_RwwksiIvOs",
    "tags": []
   },
   "source": [
    "# **[DONT RUN] Finding Labels (Don't Need To Look At - Commented Out)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4adrncBqNdo3"
   },
   "outputs": [],
   "source": [
    "# path = Path(\"\")\n",
    "\n",
    "# video_parent = path\n",
    "# split_video_path = path\n",
    "# split_csv = load_label(path / f'annotations/val.csv')\n",
    "# split_videos = list(split_video_path.glob('*.mp4'))\n",
    "# split_videos = {str(p.stem)[:11]:p for p in split_videos}\n",
    "# split_final = {split_videos[k]:split_csv[k] for k in split_csv.keys() & split_videos.keys()}\n",
    "# labels = set(split_final.values())\n",
    "# for label in labels:\n",
    "#     label_pth = split_video_path / label\n",
    "#     label_pth.mkdir(exist_ok=True, parents=True)\n",
    "# split = \"val\"\n",
    "# for vid_pth, label in tqdm(split_final.items(), desc=f'Progress {split}'):\n",
    "#     dst_vid = \"/content/drive/MyDrive/COS429/kinetics-dataset/validate\" / split_video_path / label / vid_pth.name\n",
    "#     shutil.move(vid_pth.resolve(), dst_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_CkmWqoSrXJ7"
   },
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "# path = Path(\"\")\n",
    "# split_csv = load_label(path / f'annotations/val.csv')\n",
    "# split_videos = []\n",
    "# split_videos = list(split_video_path.glob('*.mp4'))\n",
    "# split_videos = {str(p.stem)[:11]:p for p in split_videos}\n",
    "# split_final = {split_videos[k]:split_csv[k] for k in split_csv.keys() & split_videos.keys()}\n",
    "# labels = set(split_final.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "T0sJxBfjI1XM"
   },
   "outputs": [],
   "source": [
    "# def load_label(csv):\n",
    "#     table = np.loadtxt(csv, skiprows=1, dtype=str, delimiter=',')\n",
    "#     return {k: v.replace('\"', '') for k, v in zip(table[:, 1], table[:, 0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M54CD7BsHswL"
   },
   "outputs": [],
   "source": [
    "# from glob import glob\n",
    "# labels = glob(\"*/\", recursive = True)\n",
    "# labels = [sub[: -1] for sub in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cB3FauEcIR3n"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"kinetics-dataset/labels.pickle\", \"rb\") as fp:   # Unpickling\n",
    "#     labels = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JWPjeZhCGQZ-"
   },
   "outputs": [],
   "source": [
    "# #Be at /content/drive/MyDrive/COS429 when you run this \n",
    "# from pathlib import Path\n",
    "# video_paths = []\n",
    "# master_video_path = Path(\"kinetics-dataset/val\")\n",
    "# for label in labels:\n",
    "#   new_path = master_video_path / label\n",
    "#   video_paths.extend(list(new_path.glob('*.mp4')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kCherJyvWIPH"
   },
   "outputs": [],
   "source": [
    "# with open('kinetics-dataset/video_paths.pickle', 'wb') as f:\n",
    "#     pickle.dump(video_paths, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_U0Sl1s_QxU"
   },
   "source": [
    "# **[RUN] Run the Following to Initialize Params for the Baselines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683338068411,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "Gfp3S_OXX4_-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1683338069070,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "7o6U23sMWPor",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('kinetics-dataset/video_paths.pickle', 'rb') as f:\n",
    "    video_paths = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1683338069072,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "nsyQie_ySL1V",
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open('data/kinetics400/validate/validate.json')\n",
    "annotations_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1683338069073,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "krcb4waxGjCj",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "from model import VideoMAEModel\n",
    "from clip_sampler import get_frames_from_video_path\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import av\n",
    "import json\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "from experiments import run_experiment\n",
    "from experiments_runall import run_experiment_all\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3380,
     "status": "ok",
     "timestamp": 1683338072445,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "_rKhl897Gq8H",
    "outputId": "084f4844-8280-492e-f40e-5cfa3ec9efdb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "model = VideoMAEModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wD-jormHJ0lh"
   },
   "source": [
    "# **Baseline 0.1: Randomly Sample 16 Frames (Sequential)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "executionInfo": {
     "elapsed": 110405,
     "status": "error",
     "timestamp": 1683338182846,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "EDhKVkFwZ4st",
    "outputId": "c3b01249-4132-4932-cfdf-230236d3bdea",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run experiment\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3808818/1114266913.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(video_paths)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random-sequential\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/gpfs/blou/cos429-final-project/experiments.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model, sampling_strategy, video_paths, batch_size, outer_batch_size, num_examples, num_frames, frame_rate, seed)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mflow_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pickle_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flow_dict.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mflow_id_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pickle_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flow_id_dict.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gpfs/blou/cos429-final-project/utils.py\u001b[0m in \u001b[0;36mload_pickle_file\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pickle_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muniform_sample_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_of_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported pickle protocol: 5"
     ]
    }
   ],
   "source": [
    "# print(video_paths)\n",
    "run_experiment(model, \"random-sequential\", video_paths, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgIUIoglBhzS"
   },
   "source": [
    "# **Baseline 0.2: Random Sample 16 Frames (Non-Sequential)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1082353,
     "status": "ok",
     "timestamp": 1683227037318,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "HLtGjy0OBuiU",
    "outputId": "7e6a75c0-aff0-4c61-f7b4-f64559b0952c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment(model, \"completely-random\", video_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kj4H01SDdNtJ"
   },
   "source": [
    "# **Baseline 1: Randomly Sample 1 Frame of the Video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9BIyi4T-_3G",
    "outputId": "6042fb10-60cb-4720-f5b2-eb482f143c4c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment(model, \"one-random\", video_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swPrH42tB5Z8"
   },
   "source": [
    "# **Baseline 2: Get 16 Frames - One Frame From Each Fourth of the Video**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEZQogEnPrgr"
   },
   "source": [
    "**Basically, we sample one frame from the first 1/4th of the video, one from 1/4th to 1/2th way in the video, one from 1/2 to 3/4th of the video, and the last fourth. We multiply each of those frames by four to get 16 frames.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "executionInfo": {
     "elapsed": 37631,
     "status": "error",
     "timestamp": 1683303514689,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "6UxfzzzyTG1T",
    "outputId": "4abbbdfa-8b6f-4275-9d25-b4c5b8aa2bb4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment(model, \"fourths\", video_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as6cBbSTPaFx",
    "tags": []
   },
   "source": [
    "# **VIDEO VISUALIZATION (ASIDE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1683261671807,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "f5DJ3IHIKsLQ",
    "outputId": "cc851a29-84f5-42bd-a59c-8ba9cd44a64b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "indices = random.sample(range(0, len(video_paths)), 100)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7965,
     "status": "ok",
     "timestamp": 1683263854311,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "MMFbsdxHVT1f",
    "outputId": "e6fcb5f8-53b8-4470-d707-7a5600abc1fa"
   },
   "outputs": [],
   "source": [
    "video_path = video_paths[400]\n",
    "video_frames = get_frames_from_video_path(\"fourths\", video_path, 16, 1)\n",
    "predicted_label, label_num, logits = model.get_predicted_label(video_frames)\n",
    "actual_label = video_path.parent.name\n",
    "print(predicted_label)\n",
    "print(actual_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "executionInfo": {
     "elapsed": 3528,
     "status": "ok",
     "timestamp": 1683263655150,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "Lh61Hjc6A1pq",
    "outputId": "e03fde5d-8c32-4f82-c6f7-bcb18d93ff3d"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "mp4 = open(str(video_paths[400]),'rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_zSen66CJbM"
   },
   "source": [
    "# **Baseline 3: Use Optical Flow - Smart Sampling Strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqdElEmbU_Uf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683313912448,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "PR0T00lzTqsr",
    "outputId": "d1db204e-79e9-4855-8e90-7ee80bf3a69f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "indices = random.sample(range(0, len(video_paths)), 100)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiAeaZlEU7eZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for index in tqdm(indices):\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHHUjksoYADu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_path = video_paths[450]\n",
    "container = av.open(str(video_path.resolve()))\n",
    "seg_len = container.streams.video[0].frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "error",
     "timestamp": 1683313854814,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "EYpVRQhOzwi9",
    "outputId": "4601308a-0087-482e-9892-b34a5d26143b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = get_frames_from_video_path(\"all\", video_paths[450], 16, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "error",
     "timestamp": 1683313940546,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "AcQz0OLWXduz",
    "outputId": "b8ffced0-adeb-40c8-a7ee-6ee0ef249204",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_examples = 100\n",
    "indices = np.arange(start = 0, stop = seg_len, step = int(seg_len/num_examples))\n",
    "print(indices)\n",
    "print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdmWTz15rv-F",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_frames_from_container\n",
    "frames = get_frames_from_container(container, indices, format_type = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12YXwCW2tMKK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "flow_values = []\n",
    "for i in range(0, len(frames) - 1):\n",
    "    flow = np.linalg.norm(cv.calcOpticalFlowFarneback(frames[i], frames[i + 1], None, 0.5, 3, 15, 3, 5, 1.2, 0))\n",
    "    flow_values.append(flow)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1683303856424,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "ZDGPswQN2-Mj",
    "outputId": "29413ac6-a202-4999-f04d-9541fd644c8c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "plt.plot(flow_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 4: Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run experiment\n",
      "Iteration 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:: 100%|██████████| 250/250 [39:45<00:00,  9.54s/it]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for obj-detection-top16: 0.788\n",
      "Accuracy for obj-detection-low16: 0.728\n",
      "Accuracy for obj-detection-top8: 0.704\n",
      "Accuracy for obj-detection-top4: 0.644\n",
      "Accuracy for obj-detection-top1: 0.576\n",
      "Accuracy for obj-detection-mixed: 0.8\n"
     ]
    }
   ],
   "source": [
    "run_experiment_all(model, \"obj-detection-all\", video_paths, seed = 10, num_frames=16, num_examples = 250, outer_batch_size = 250, batch_size = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run experiment\n",
      "Iteration 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing::   0%|          | 0/250 [00:00<?, ?it/s]/home/blou/.conda/envs/cos429/lib/python3.7/site-packages/transformers/feature_extraction_utils.py:147: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  return torch.tensor(value)\n",
      "Preprocessing:: 100%|██████████| 250/250 [07:59<00:00,  1.92s/it]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:08<00:00,  1.17it/s]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]\n",
      "Evaluating:: 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for position-fourths: 0.66\n",
      "Accuracy for position_beginning: 0.748\n",
      "Accuracy for position_middle: 0.784\n",
      "Accuracy for position_end: 0.764\n",
      "Accuracy for position-mixed: 0.816\n"
     ]
    }
   ],
   "source": [
    "run_experiment_all(model, \"position-all\", video_paths, seed = 10, num_frames=16, num_examples = 250, outer_batch_size = 250, batch_size = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vmvqn1Leyvos"
   },
   "source": [
    "- Audio\n",
    "- Pose Detection \n",
    "- Non Ordered, Non Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAbk6rKozYiu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"outputs/random-sequential_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1683306018004,
     "user": {
      "displayName": "Ameya Vaidya",
      "userId": "10785321624963506716"
     },
     "user_tz": 240
    },
    "id": "voSMt77X22Li",
    "outputId": "47594a4f-7ec7-4b51-a1ef-72c03b9dccc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-162725e6-544a-4a67-ac09-fe649a706978\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Video Path</th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Sampling Strategy</th>\n",
       "      <th>Video Index</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sword fighting</td>\n",
       "      <td>sword fighting</td>\n",
       "      <td>kinetics-dataset/val/sword fighting/WGztQjJ0aM...</td>\n",
       "      <td>WGztQjJ0aMU</td>\n",
       "      <td>random-sequential</td>\n",
       "      <td>4680</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grooming horse</td>\n",
       "      <td>grooming horse</td>\n",
       "      <td>kinetics-dataset/val/grooming horse/1RYKyKAYZO...</td>\n",
       "      <td>1RYKyKAYZOQ</td>\n",
       "      <td>random-sequential</td>\n",
       "      <td>266</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crying</td>\n",
       "      <td>crying</td>\n",
       "      <td>kinetics-dataset/val/crying/IfFZalicJ_U_000001...</td>\n",
       "      <td>IfFZalicJ_U</td>\n",
       "      <td>random-sequential</td>\n",
       "      <td>3513</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spraying</td>\n",
       "      <td>spraying</td>\n",
       "      <td>kinetics-dataset/val/spraying/NPYa_aJXLyk_0004...</td>\n",
       "      <td>NPYa_aJXLyk</td>\n",
       "      <td>random-sequential</td>\n",
       "      <td>3953</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>playing ice hockey</td>\n",
       "      <td>playing ice hockey</td>\n",
       "      <td>kinetics-dataset/val/playing ice hockey/7D4VHp...</td>\n",
       "      <td>7D4VHpfoPak</td>\n",
       "      <td>random-sequential</td>\n",
       "      <td>4735</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>using remote controller (not gaming)</td>\n",
       "      <td>using remote controller (not gaming)</td>\n",
       "      <td>kinetics-dataset/val/using remote controller (...</td>\n",
       "      <td>iKJ_R-CB1oI</td>\n",
       "      <td>random-sequential</td>\n",
       "      <td>6333</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>digging</td>\n",
       "      <td>blasting sand</td>\n",
       "      <td>kinetics-dataset/val/digging/hBMLJRNjjso_00000...</td>\n",
       "      <td>hBMLJRNjjso</td>\n",
       "      <td>random-sequential</td>\n",
       "      <td>791</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>skateboarding</td>\n",
       "      <td>skateboarding</td>\n",
       "      <td>kinetics-dataset/val/skateboarding/hYK_Jcr-N-o...</td>\n",
       "      <td>hYK_Jcr-N-o</td>\n",
       "      <td>random-sequential</td>\n",
       "      <td>3617</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>auctioning</td>\n",
       "      <td>making tea</td>\n",
       "      <td>kinetics-dataset/val/auctioning/JzAYnk-gf4Y_00...</td>\n",
       "      <td>JzAYnk-gf4Y</td>\n",
       "      <td>random-sequential</td>\n",
       "      <td>1362</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>trimming trees</td>\n",
       "      <td>trimming trees</td>\n",
       "      <td>kinetics-dataset/val/trimming trees/5H02ohmoKo...</td>\n",
       "      <td>5H02ohmoKow</td>\n",
       "      <td>random-sequential</td>\n",
       "      <td>6614</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-162725e6-544a-4a67-ac09-fe649a706978')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-162725e6-544a-4a67-ac09-fe649a706978 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-162725e6-544a-4a67-ac09-fe649a706978');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                            Actual Label  \\\n",
       "0                         sword fighting   \n",
       "1                         grooming horse   \n",
       "2                                 crying   \n",
       "3                               spraying   \n",
       "4                     playing ice hockey   \n",
       "..                                   ...   \n",
       "95  using remote controller (not gaming)   \n",
       "96                               digging   \n",
       "97                         skateboarding   \n",
       "98                            auctioning   \n",
       "99                        trimming trees   \n",
       "\n",
       "                         Predicted Label  \\\n",
       "0                         sword fighting   \n",
       "1                         grooming horse   \n",
       "2                                 crying   \n",
       "3                               spraying   \n",
       "4                     playing ice hockey   \n",
       "..                                   ...   \n",
       "95  using remote controller (not gaming)   \n",
       "96                         blasting sand   \n",
       "97                         skateboarding   \n",
       "98                            making tea   \n",
       "99                        trimming trees   \n",
       "\n",
       "                                           Video Path     Video ID  \\\n",
       "0   kinetics-dataset/val/sword fighting/WGztQjJ0aM...  WGztQjJ0aMU   \n",
       "1   kinetics-dataset/val/grooming horse/1RYKyKAYZO...  1RYKyKAYZOQ   \n",
       "2   kinetics-dataset/val/crying/IfFZalicJ_U_000001...  IfFZalicJ_U   \n",
       "3   kinetics-dataset/val/spraying/NPYa_aJXLyk_0004...  NPYa_aJXLyk   \n",
       "4   kinetics-dataset/val/playing ice hockey/7D4VHp...  7D4VHpfoPak   \n",
       "..                                                ...          ...   \n",
       "95  kinetics-dataset/val/using remote controller (...  iKJ_R-CB1oI   \n",
       "96  kinetics-dataset/val/digging/hBMLJRNjjso_00000...  hBMLJRNjjso   \n",
       "97  kinetics-dataset/val/skateboarding/hYK_Jcr-N-o...  hYK_Jcr-N-o   \n",
       "98  kinetics-dataset/val/auctioning/JzAYnk-gf4Y_00...  JzAYnk-gf4Y   \n",
       "99  kinetics-dataset/val/trimming trees/5H02ohmoKo...  5H02ohmoKow   \n",
       "\n",
       "    Sampling Strategy  Video Index  Correct  \n",
       "0   random-sequential         4680     True  \n",
       "1   random-sequential          266     True  \n",
       "2   random-sequential         3513     True  \n",
       "3   random-sequential         3953     True  \n",
       "4   random-sequential         4735     True  \n",
       "..                ...          ...      ...  \n",
       "95  random-sequential         6333     True  \n",
       "96  random-sequential          791    False  \n",
       "97  random-sequential         3617     True  \n",
       "98  random-sequential         1362    False  \n",
       "99  random-sequential         6614     True  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "z_RwwksiIvOs",
    "o_U0Sl1s_QxU",
    "sgIUIoglBhzS",
    "Kj4H01SDdNtJ",
    "swPrH42tB5Z8",
    "as6cBbSTPaFx",
    "J_zSen66CJbM"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
